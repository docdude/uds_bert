{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09f03daf",
   "metadata": {},
   "source": [
    "# Breast Cancer Screening UDS Prototype (2025)\n",
    "\n",
    "This notebook ingests:\n",
    "- Scanned mammogram reports (PDF) via OCR\n",
    "- Breast imaging CSV extract (mammograms, tomosynthesis)\n",
    "\n",
    "It outputs per-patient breast cancer screening numerator status for 2025 with an auditor-friendly evidence string.\n",
    "\n",
    "## UDS 2025 Breast Cancer Screening Rules:\n",
    "- **Mammogram (including digital tomosynthesis)**: Within 2 years (2024-2025)\n",
    "- Age range: Typically 50-74 years (verify with your UDS specifications)\n",
    "- Includes: screening mammogram, diagnostic mammogram, digital breast tomosynthesis (DBT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8ef553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, json, datetime as dt\n",
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd331265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "\n",
    "# Auto-discover breast cancer screening PDFs\n",
    "PDF_GLOBS = [\n",
    "    \"pdf_data/*mammo*.pdf\",\n",
    "    \"pdf_data/*mammogram*.pdf\",\n",
    "    \"pdf_data/*breast*.pdf\",\n",
    "    \"pdf_data/*tomosynthesis*.pdf\",\n",
    "    \"pdf_data/*dbt*.pdf\",\n",
    "]\n",
    "PDF_PATHS = sorted({p for g in PDF_GLOBS for p in glob.glob(g)})\n",
    "\n",
    "BREAST_CSV_PATH = \"csv_data/breast_screening.csv\"\n",
    "REPORTING_YEAR = 2025\n",
    "\n",
    "print(f\"Found {len(PDF_PATHS)} PDFs:\")\n",
    "for p in PDF_PATHS:\n",
    "    print(\" -\", os.path.basename(p))\n",
    "print(\"Breast screening CSV:\", os.path.basename(BREAST_CSV_PATH), \"exists:\", os.path.exists(BREAST_CSV_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "283cc3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, datetime as dt\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Literal, Dict, Any, List, Tuple\n",
    "\n",
    "DATE_PAT = re.compile(r'(\\d{1,2})[/-](\\d{1,2})[/-](\\d{2,4})')\n",
    "# Match dates with month names like \"April 02, 2018\" or \"April 2, 2018\"\n",
    "MONTH_NAME_PAT = re.compile(r'\\b(January|February|March|April|May|June|July|August|September|October|November|December|Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Sept|Oct|Nov|Dec)\\.?\\s+(\\d{1,2}),?\\s+(\\d{4})\\b', re.IGNORECASE)\n",
    "\n",
    "def _to_iso(m:int,d:int,y:int) -> Optional[str]:\n",
    "    if y < 100:\n",
    "        y = 2000 + y if y < 50 else 1900 + y\n",
    "    try:\n",
    "        return dt.date(y,m,d).isoformat()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def parse_dates(text: str) -> List[Tuple[str, str]]:\n",
    "    out=[]\n",
    "    # Extract numeric dates like 4/2/2018\n",
    "    for m,d,y in DATE_PAT.findall(text or \"\"):\n",
    "        iso = _to_iso(int(m), int(d), int(y))\n",
    "        if iso:\n",
    "            out.append((iso, f\"{m}/{d}/{y}\"))\n",
    "    \n",
    "    # Extract dates with month names like \"April 02, 2018\"\n",
    "    month_map = {\n",
    "        'jan': 1, 'january': 1, 'feb': 2, 'february': 2, 'mar': 3, 'march': 3,\n",
    "        'apr': 4, 'april': 4, 'may': 5, 'jun': 6, 'june': 6,\n",
    "        'jul': 7, 'july': 7, 'aug': 8, 'august': 8, 'sep': 9, 'sept': 9, 'september': 9,\n",
    "        'oct': 10, 'october': 10, 'nov': 11, 'november': 11, 'dec': 12, 'december': 12\n",
    "    }\n",
    "    for month_name, day, year in MONTH_NAME_PAT.findall(text or \"\"):\n",
    "        month_num = month_map.get(month_name.lower())\n",
    "        if month_num:\n",
    "            iso = _to_iso(month_num, int(day), int(year))\n",
    "            if iso:\n",
    "                out.append((iso, f\"{month_name} {day}, {year}\"))\n",
    "    \n",
    "    return out\n",
    "\n",
    "def looks_like_nonclinical_line(line: str) -> bool:\n",
    "    l=(line or \"\").lower()\n",
    "    if \"electronically signed\" in l or \"signed by\" in l:\n",
    "        return True\n",
    "    if \"dob\" in l or \"date of birth\" in l:\n",
    "        return True\n",
    "    if \"data:text\" in l or \"base64\" in l:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def filename_patient_id(path: str) -> str:\n",
    "    base=os.path.basename(path)\n",
    "    m=re.match(r'^(\\d+)', base)\n",
    "    return m.group(1) if m else base\n",
    "\n",
    "import pdfplumber\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "\n",
    "KEYWORDS = [\"mammogram\",\"mammography\",\"breast\",\"tomosynthesis\",\"dbt\",\"screening\",\"diagnostic\",\"birads\",\"bi-rads\"]\n",
    "\n",
    "# POPPLER PATH: Uncomment and set this if poppler is not in your system PATH\n",
    "POPPLER_PATH = r\"C:\\poppler\\Library\\bin\"\n",
    "\n",
    "# TESSERACT PATH: Set path to tesseract executable\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Users\\jloya\\AppData\\Local\\Programs\\Tesseract-OCR\\tesseract.exe\"\n",
    "#POPPLER_PATH = None  # Set to None to use system PATH\n",
    "\n",
    "def extract_first_page_text(pdf_path: str, ocr_dpi: int = 300, min_chars: int = 80, max_pages: int = 5) -> str:\n",
    "    \"\"\"Extract text from PDF, checking multiple pages if needed. Uses OCR fallback for scanned documents.\"\"\"\n",
    "    all_text = \"\"\n",
    "    \n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            total_pages = len(pdf.pages)\n",
    "            pages_to_check = min(max_pages, total_pages)\n",
    "            \n",
    "            # Try extracting from first few pages\n",
    "            for page_num in range(pages_to_check):\n",
    "                page_text = (pdf.pages[page_num].extract_text() or \"\")\n",
    "                all_text += page_text + \"\\n\"\n",
    "                \n",
    "                # Check if we have enough clinical content\n",
    "                text_l = all_text.lower()\n",
    "                keyword_hit = any(k in text_l for k in KEYWORDS)\n",
    "                if len(all_text.strip()) >= min_chars and keyword_hit:\n",
    "                    # Found good content, stop here\n",
    "                    return all_text\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # If we didn't get good text, try OCR on first few pages\n",
    "    if len(all_text.strip()) < min_chars or not any(k in all_text.lower() for k in KEYWORDS):\n",
    "        try:\n",
    "            ocr_combined = \"\"\n",
    "            # OCR up to max_pages or until we find clinical content\n",
    "            for page_num in range(1, min(max_pages + 1, 15)):  # Cap at 15 pages max\n",
    "                pages = convert_from_path(\n",
    "                    pdf_path, \n",
    "                    dpi=ocr_dpi, \n",
    "                    first_page=page_num, \n",
    "                    last_page=page_num,\n",
    "                    poppler_path=POPPLER_PATH\n",
    "                )\n",
    "                if pages:\n",
    "                    ocr_text = pytesseract.image_to_string(pages[0], timeout=12)\n",
    "                    ocr_combined += ocr_text + \"\\n\"\n",
    "                    \n",
    "                    # Check if we found clinical content\n",
    "                    ocr_l = ocr_combined.lower()\n",
    "                    keyword_hit = any(k in ocr_l for k in KEYWORDS)\n",
    "                    if len(ocr_combined.strip()) >= min_chars and keyword_hit:\n",
    "                        # Found good OCR content, stop here\n",
    "                        return ocr_combined\n",
    "                        \n",
    "            # Return whatever OCR we got if it's better than pdfplumber\n",
    "            if len(ocr_combined.strip()) > len(all_text.strip()):\n",
    "                return ocr_combined\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    \n",
    "    # Return whatever we got, even if minimal\n",
    "    return all_text or \"\"\n",
    "\n",
    "    # OCR fallback - CRITICAL for scanned PDFs\n",
    "    try:\n",
    "        pages = convert_from_path(\n",
    "            pdf_path, \n",
    "            dpi=ocr_dpi, \n",
    "            first_page=1, \n",
    "            last_page=1,\n",
    "            poppler_path=POPPLER_PATH\n",
    "        )\n",
    "        if pages:\n",
    "            ocr_text = pytesseract.image_to_string(pages[0], timeout=12)\n",
    "            if ocr_text and len(ocr_text.strip()) > len(text.strip()):\n",
    "                return ocr_text\n",
    "    except Exception as e:\n",
    "        # OCR failed - likely poppler not installed\n",
    "        pass\n",
    "    \n",
    "    # Return whatever we got, even if minimal\n",
    "    return text or \"\"\n",
    "\n",
    "EventType = Literal[\"SCREENING_MAMMOGRAM\",\"DIAGNOSTIC_MAMMOGRAM\",\"TOMOSYNTHESIS\"]\n",
    "\n",
    "@dataclass\n",
    "class ScreeningEvent:\n",
    "    patient_id: str\n",
    "    event_type: EventType\n",
    "    event_date: Optional[str]\n",
    "    source: Literal[\"pdf\",\"structured_csv\"]\n",
    "    confidence: float\n",
    "    needs_review: bool\n",
    "    evidence: Dict[str, Any]\n",
    "\n",
    "def classify_doc(text: str) -> Optional[EventType]:\n",
    "    \"\"\"Classify breast cancer screening document type.\"\"\"\n",
    "    t=(text or \"\").lower()\n",
    "    \n",
    "    # Check for tomosynthesis/DBT first (most specific)\n",
    "    if re.search(r'\\b(tomosynthesis|dbt|3d\\s*mammo)\\b', t):\n",
    "        return \"TOMOSYNTHESIS\"\n",
    "    \n",
    "    # Check for mammogram type\n",
    "    if \"mammogram\" in t or \"mammography\" in t:\n",
    "        # Try to determine if screening vs diagnostic\n",
    "        if re.search(r'\\b(screening|screen|routine|annual)\\b', t):\n",
    "            return \"SCREENING_MAMMOGRAM\"\n",
    "        elif re.search(r'\\b(diagnostic|diagnosis|follow[\\s-]?up|callback|additional)\\b', t):\n",
    "            return \"DIAGNOSTIC_MAMMOGRAM\"\n",
    "        else:\n",
    "            # Default to screening if type unclear\n",
    "            return \"SCREENING_MAMMOGRAM\"\n",
    "    \n",
    "    # General breast imaging mention\n",
    "    if \"breast\" in t and (\"imaging\" in t or \"radiology\" in t or \"exam\" in t):\n",
    "        return \"SCREENING_MAMMOGRAM\"\n",
    "    \n",
    "    return None\n",
    "\n",
    "def extract_labeled_dates(text: str) -> Dict[str, List[str]]:\n",
    "    labels = {\"exam\":[],\"procedure\":[],\"study\":[],\"received\":[],\"result\":[],\"other\":[]}\n",
    "    for line in (text or \"\").splitlines():\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        if looks_like_nonclinical_line(line):\n",
    "            continue\n",
    "        ll=line.lower()\n",
    "        label=\"other\"\n",
    "        if re.search(r'exam\\s*date|date\\s*of\\s*exam', ll):\n",
    "            label=\"exam\"\n",
    "        elif re.search(r'procedure\\s*date|date\\s*of\\s*procedure|date\\s*of\\s*service|\\bdos\\b', ll):\n",
    "            label=\"procedure\"\n",
    "        elif re.search(r'study\\s*date|date\\s*of\\s*study', ll):\n",
    "            label=\"study\"\n",
    "        elif re.search(r'\\breceived\\b', ll):\n",
    "            label=\"received\"\n",
    "        elif re.search(r'\\bresult\\b|\\breported\\b|\\bfinal\\b', ll):\n",
    "            label=\"result\"\n",
    "        # Pattern for \"performed on MM/DD/YYYY\" or \"on MM/DD/YYYY\"\n",
    "        if re.search(r'\\b(performed|on)\\s*\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}\\b', ll):\n",
    "            label=\"exam\"\n",
    "        for iso,_ in parse_dates(line):\n",
    "            labels[label].append(iso)\n",
    "    for k,v in labels.items():\n",
    "        seen=set(); nv=[]\n",
    "        for d in v:\n",
    "            if d not in seen:\n",
    "                nv.append(d); seen.add(d)\n",
    "        labels[k]=nv\n",
    "    return labels\n",
    "\n",
    "def is_reasonable_procedure_date(date_iso: str) -> bool:\n",
    "    \"\"\"Filter out dates that are clearly not procedure dates (e.g., DOBs from 1950s)\"\"\"\n",
    "    try:\n",
    "        year = int(date_iso[:4])\n",
    "        # Mammography screening should be in a reasonable range\n",
    "        # Allow 1995-present (30 years back) to be safe\n",
    "        return 1995 <= year <= (dt.date.today().year + 1)\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def choose_best_date(event_type: EventType, labeled: Dict[str,List[str]], all_dates: List[str]) -> Tuple[Optional[str], float, bool, str]:\n",
    "    # For mammograms, prefer exam/procedure/study date\n",
    "    pref=\"exam\"\n",
    "    \n",
    "    candidates = labeled.get(\"exam\", []).copy()\n",
    "    if not candidates:\n",
    "        candidates = labeled.get(\"procedure\",[])\n",
    "    if not candidates:\n",
    "        candidates = labeled.get(\"study\",[])\n",
    "    if not candidates:\n",
    "        candidates = labeled.get(\"result\",[]) + labeled.get(\"received\",[]) + labeled.get(\"other\",[])\n",
    "    if not candidates and all_dates:\n",
    "        candidates = list(dict.fromkeys(all_dates))\n",
    "\n",
    "    if not candidates:\n",
    "        return None, 0.2, True, \"no date found\"\n",
    "\n",
    "    # Apply stricter date filtering to exclude DOB-era dates\n",
    "    filtered = [d for d in candidates if is_reasonable_procedure_date(d)]\n",
    "    \n",
    "    if not filtered:\n",
    "        # All dates were filtered out (probably DOBs)\n",
    "        return None, 0.1, True, f\"dates found but all appear to be DOBs or invalid: {candidates}\"\n",
    "    \n",
    "    candidates = filtered\n",
    "\n",
    "    best = max(candidates)\n",
    "    conf = 0.9 if ((labeled.get(\"exam\") and best in labeled[\"exam\"]) or \n",
    "                   (labeled.get(\"procedure\") and best in labeled[\"procedure\"]) or\n",
    "                   (labeled.get(\"study\") and best in labeled[\"study\"])) else 0.65\n",
    "    needs_review = False\n",
    "    rationale = f\"picked {best} from {pref if conf>0.8 else 'fallback'}\"\n",
    "\n",
    "    distinct = sorted(set(sum(labeled.values(), [])))\n",
    "    if conf < 0.8 and len(distinct) >= 2:\n",
    "        needs_review = True\n",
    "        conf = min(conf, 0.55)\n",
    "        rationale += \"; multiple conflicting dates\"\n",
    "\n",
    "    return best, conf, needs_review, rationale\n",
    "\n",
    "def extract_event_from_pdf(pdf_path: str, text: str) -> ScreeningEvent:\n",
    "    pid = filename_patient_id(pdf_path)\n",
    "    filename = os.path.basename(pdf_path).lower()\n",
    "    \n",
    "    # Try to classify from text content first\n",
    "    et = classify_doc(text)\n",
    "    if et is None:\n",
    "        # Fallback to filename-based classification\n",
    "        if \"tomosynthesis\" in filename or \"dbt\" in filename:\n",
    "            et = \"TOMOSYNTHESIS\"\n",
    "        elif \"diagnostic\" in filename:\n",
    "            et = \"DIAGNOSTIC_MAMMOGRAM\"\n",
    "        elif \"mammo\" in filename or \"breast\" in filename:\n",
    "            et = \"SCREENING_MAMMOGRAM\"\n",
    "        else:\n",
    "            et = \"SCREENING_MAMMOGRAM\"  # Default assumption\n",
    "    \n",
    "    labeled = extract_labeled_dates(text)\n",
    "    all_dates = [d for d,_ in parse_dates(text)]\n",
    "    best_date, conf, needs_review, rationale = choose_best_date(et, labeled, all_dates)\n",
    "\n",
    "    lines = [ln.strip() for ln in (text or \"\").splitlines() if ln.strip()]\n",
    "    keys = [\"mammogram\", \"mammography\", \"breast\", \"tomosynthesis\", \"screening\", \"diagnostic\", \n",
    "            \"birads\", \"bi-rads\", \"impression\", \"findings\", \"exam\", \"study\", \"procedure\"]\n",
    "    \n",
    "    snippet_lines = []\n",
    "    for ln in lines:\n",
    "        lnl = ln.lower()\n",
    "        if any(k in lnl for k in keys):\n",
    "            snippet_lines.append(ln)\n",
    "        if len(snippet_lines) >= 8:\n",
    "            break\n",
    "    snippet = (\" \".join(snippet_lines) or (text or \"\")[:600]).replace(chr(10), \" \")\n",
    "\n",
    "    # If text was minimal (likely failed OCR), mark for review and note filename-based classification\n",
    "    text_minimal = len(text.strip()) < 100\n",
    "    if text_minimal:\n",
    "        needs_review = True\n",
    "        conf = min(conf, 0.6)\n",
    "        if best_date:\n",
    "            rationale += f\"; text extraction minimal ({len(text.strip())} chars), classified by filename\"\n",
    "        else:\n",
    "            rationale = f\"text extraction minimal ({len(text.strip())} chars), classified by filename, no valid date\"\n",
    "\n",
    "    # If no confident exam date, flag for review\n",
    "    if best_date is None or conf < 0.8:\n",
    "        needs_review = True\n",
    "\n",
    "    return ScreeningEvent(\n",
    "        patient_id=pid,\n",
    "        event_type=et,\n",
    "        event_date=best_date,\n",
    "        source=\"pdf\",\n",
    "        confidence=float(conf),\n",
    "        needs_review=bool(needs_review),\n",
    "        evidence={\n",
    "            \"file\": os.path.basename(pdf_path),\n",
    "            \"rationale\": rationale,\n",
    "            \"snippet\": snippet,\n",
    "            \"dates_by_label\": labeled,\n",
    "            \"text_length\": len(text),\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03e7dbe6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PDF_PATHS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Extract events from PDFs (fast text extraction with OCR fallback)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m pdf_rows\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pdf_path \u001b[38;5;129;01min\u001b[39;00m \u001b[43mPDF_PATHS\u001b[49m:\n\u001b[0;32m      4\u001b[0m     text \u001b[38;5;241m=\u001b[39m extract_first_page_text(pdf_path)\n\u001b[0;32m      5\u001b[0m     ev \u001b[38;5;241m=\u001b[39m extract_event_from_pdf(pdf_path, text)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PDF_PATHS' is not defined"
     ]
    }
   ],
   "source": [
    "# Extract events from PDFs (fast text extraction with OCR fallback)\n",
    "pdf_rows=[]\n",
    "for pdf_path in PDF_PATHS:\n",
    "    text = extract_first_page_text(pdf_path)\n",
    "    ev = extract_event_from_pdf(pdf_path, text)\n",
    "    pdf_rows.append(ev.__dict__)\n",
    "\n",
    "df_pdf = pd.DataFrame(pdf_rows)\n",
    "df_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238fe2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse breast screening CSV extract and convert to ScreeningEvent rows\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "def detect_header_row(csv_path: str, max_scan: int = 40) -> int:\n",
    "    with open(csv_path, 'r', errors='ignore') as f:\n",
    "        for i,line in enumerate(f):\n",
    "            if i>max_scan:\n",
    "                break\n",
    "            l=line.lower()\n",
    "            if 'person' in l and ('nbr' in l or '#' in l) and ('mrn' in l or 'enc' in l or 'date' in l):\n",
    "                return i\n",
    "    return 0\n",
    "\n",
    "# Check if CSV exists before processing\n",
    "if not os.path.exists(BREAST_CSV_PATH):\n",
    "    print(f\"⚠️ CSV file not found: {BREAST_CSV_PATH}\")\n",
    "    print(\"Creating empty dataframe for CSV events\")\n",
    "    df_csv_events = pd.DataFrame(columns=[\"patient_id\",\"event_type\",\"event_date\",\"source\",\"confidence\",\"needs_review\",\"evidence\"])\n",
    "else:\n",
    "    hdr = detect_header_row(BREAST_CSV_PATH)\n",
    "    df_csv = pd.read_csv(BREAST_CSV_PATH, header=hdr)\n",
    "    df_csv.columns = [c.strip() for c in df_csv.columns]\n",
    "\n",
    "    # Identify key columns\n",
    "    def find_col(cols, patterns):\n",
    "        for p in patterns:\n",
    "            for c in cols:\n",
    "                if re.search(p, c, re.I):\n",
    "                    return c\n",
    "        return None\n",
    "\n",
    "    pid_col = find_col(df_csv.columns, [r'person\\s*nbr', r'person\\s*#', r'patient'])\n",
    "    encdate_col = find_col(df_csv.columns, [r'enc\\s*date', r'exam\\s*date', r'study\\s*date', r'procedure\\s*date', r'date'])\n",
    "    test_col = find_col(df_csv.columns, [r'test', r'order', r'procedure', r'description', r'name', r'exam'])\n",
    "\n",
    "    def parse_any_date(x):\n",
    "        if pd.isna(x): return None\n",
    "        s=str(x).strip()\n",
    "        m=DATE_PAT.search(s)\n",
    "        if not m: \n",
    "            return None\n",
    "        mm,dd,yy = map(int, m.groups())\n",
    "        iso=_to_iso(mm,dd,yy)\n",
    "        return iso\n",
    "\n",
    "    csv_events=[]\n",
    "    for idx,row in df_csv.iterrows():\n",
    "        pid = str(row.get(pid_col, '')).strip()\n",
    "        if not pid or pid.lower()=='nan':\n",
    "            continue\n",
    "        ev_date = parse_any_date(row.get(encdate_col, None))\n",
    "        if not ev_date:\n",
    "            continue\n",
    "        test_name = str(row.get(test_col, '')).lower() if test_col else ''\n",
    "        \n",
    "        # Classify based on test name\n",
    "        if 'tomosynthesis' in test_name or 'dbt' in test_name or '3d' in test_name:\n",
    "            et = 'TOMOSYNTHESIS'\n",
    "        elif 'diagnostic' in test_name:\n",
    "            et = 'DIAGNOSTIC_MAMMOGRAM'\n",
    "        else:\n",
    "            et = 'SCREENING_MAMMOGRAM'\n",
    "        \n",
    "        csv_events.append({\n",
    "            \"patient_id\": pid,\n",
    "            \"event_type\": et,\n",
    "            \"event_date\": ev_date,\n",
    "            \"source\": \"structured_csv\",\n",
    "            \"confidence\": 0.95,\n",
    "            \"needs_review\": False,\n",
    "            \"evidence\": {\"source_file\": os.path.basename(BREAST_CSV_PATH), \"row_index\": int(idx), \"test_name\": test_name}\n",
    "        })\n",
    "\n",
    "    df_csv_events = pd.DataFrame(csv_events)\n",
    "\n",
    "df_csv_events.head() if not df_csv_events.empty else df_csv_events, df_csv_events.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50b6a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breast Cancer Screening 2025 rule engine + merge, de-dup, and scoring\n",
    "import datetime as dt\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "year_start = dt.date(REPORTING_YEAR,1,1)\n",
    "year_end = dt.date(REPORTING_YEAR,12,31)\n",
    "\n",
    "def counts_for_breast_screening(event_type: str, event_date_iso: str) -> bool:\n",
    "    \"\"\"\n",
    "    UDS 2025 Breast Cancer Screening Rules:\n",
    "    - Mammogram (all types): Within 2 years (2024-2025)\n",
    "    - Includes screening, diagnostic, and tomosynthesis\n",
    "    \"\"\"\n",
    "    if not event_date_iso:\n",
    "        return False\n",
    "    d = dt.date.fromisoformat(event_date_iso)\n",
    "    \n",
    "    # All mammogram types: 2 year lookback (within 27 months to be safe)\n",
    "    # 2024-01-01 through 2025-12-31\n",
    "    return (year_start - relativedelta(years=1)) <= d <= year_end\n",
    "\n",
    "# Merge PDF and CSV events\n",
    "df_all = pd.concat([\n",
    "    df_pdf[[\"patient_id\",\"event_type\",\"event_date\",\"source\",\"confidence\",\"needs_review\",\"evidence\"]],\n",
    "    df_csv_events[[\"patient_id\",\"event_type\",\"event_date\",\"source\",\"confidence\",\"needs_review\",\"evidence\"]],\n",
    "], ignore_index=True)\n",
    "\n",
    "# De-dup: keep highest confidence for same patient/type/date\n",
    "df_all[\"dedup_key\"] = df_all[\"patient_id\"].astype(str)+\"|\"+df_all[\"event_type\"].astype(str)+\"|\"+df_all[\"event_date\"].astype(str)\n",
    "df_all = (df_all\n",
    "          .sort_values([\"confidence\",\"source\"], ascending=[False, True])\n",
    "          .drop_duplicates(\"dedup_key\", keep=\"first\")\n",
    "          .drop(columns=[\"dedup_key\"])\n",
    "         )\n",
    "\n",
    "df_all[\"counts_breast_2025\"] = df_all.apply(lambda r: counts_for_breast_screening(r[\"event_type\"], r[\"event_date\"]), axis=1)\n",
    "df_all.sort_values([\"patient_id\",\"counts_breast_2025\",\"event_date\"], ascending=[True, False, False]).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d70b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick best numerator evidence per patient (most recent qualifying; tie-break by confidence)\n",
    "def pick_best(df):\n",
    "    q = df[df[\"counts_breast_2025\"]==True].copy()\n",
    "    if q.empty:\n",
    "        # keep best available for review (most recent date regardless) if any\n",
    "        df2 = df.copy()\n",
    "        df2 = df2[df2[\"event_date\"].notna()]\n",
    "        if df2.empty:\n",
    "            return pd.Series({\n",
    "                \"numerator_met\": False,\n",
    "                \"best_event_type\": None,\n",
    "                \"best_event_date\": None,\n",
    "                \"best_source\": None,\n",
    "                \"best_confidence\": None,\n",
    "                \"needs_review\": True,\n",
    "                \"evidence_summary\": \"no dated breast screening evidence found\",\n",
    "            })\n",
    "        df2 = df2.sort_values([\"event_date\",\"confidence\"], ascending=[False,False]).head(1)\n",
    "        row = df2.iloc[0]\n",
    "        return pd.Series({\n",
    "            \"numerator_met\": False,\n",
    "            \"best_event_type\": row.event_type,\n",
    "            \"best_event_date\": row.event_date,\n",
    "            \"best_source\": row.source,\n",
    "            \"best_confidence\": row.confidence,\n",
    "            \"needs_review\": True,\n",
    "            \"evidence_summary\": f\"Best non-qualifying evidence: {row.event_type} {row.event_date} ({row.source}); {row.evidence.get('file', row.evidence.get('source_file',''))}\",\n",
    "        })\n",
    "    q = q.sort_values([\"event_date\",\"confidence\"], ascending=[False,False]).head(1)\n",
    "    row = q.iloc[0]\n",
    "    file_or_row = row.evidence.get('file', row.evidence.get('source_file',''))\n",
    "    snippet = row.evidence.get('snippet','')\n",
    "    summary = f\"{row.event_type} on {row.event_date} via {row.source} ({file_or_row})\"\n",
    "    if snippet:\n",
    "        summary += f\" | snippet: {snippet[:160]}\"\n",
    "    return pd.Series({\n",
    "        \"numerator_met\": True,\n",
    "        \"best_event_type\": row.event_type,\n",
    "        \"best_event_date\": row.event_date,\n",
    "        \"best_source\": row.source,\n",
    "        \"best_confidence\": row.confidence,\n",
    "        \"needs_review\": bool(row.needs_review),\n",
    "        \"evidence_summary\": summary,\n",
    "    })\n",
    "\n",
    "df_best = df_all.groupby(\"patient_id\", as_index=False).apply(pick_best).reset_index(drop=True)\n",
    "df_best = df_best.sort_values([\"numerator_met\",\"needs_review\",\"best_event_date\"], ascending=[False, True, False])\n",
    "\n",
    "# Save auditor table\n",
    "os.makedirs(\"audit_data\", exist_ok=True)\n",
    "out_csv = \"audit_data/breast_screening_2025_audit_table.csv\"\n",
    "df_best.to_csv(out_csv, index=False, escapechar='\\\\', doublequote=False)\n",
    "print(f\"✓ Saved audit table to: {out_csv}\")\n",
    "out_csv, df_best.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40866d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"=\"*80)\n",
    "print(\"BREAST CANCER SCREENING UDS 2025 SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal unique patients: {len(df_best)}\")\n",
    "print(f\"Numerator met: {df_best['numerator_met'].sum()} ({df_best['numerator_met'].sum()/len(df_best)*100:.1f}%)\")\n",
    "print(f\"Needs review: {df_best['needs_review'].sum()} ({df_best['needs_review'].sum()/len(df_best)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"By Event Type:\")\n",
    "print(\"-\"*80)\n",
    "event_counts = df_best[df_best['numerator_met']==True]['best_event_type'].value_counts()\n",
    "for event_type, count in event_counts.items():\n",
    "    print(f\"  {event_type}: {count} patients\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"By Source:\")\n",
    "print(\"-\"*80)\n",
    "source_counts = df_best[df_best['numerator_met']==True]['best_source'].value_counts()\n",
    "for source, count in source_counts.items():\n",
    "    print(f\"  {source}: {count} patients\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Confidence Distribution (qualifying events):\")\n",
    "print(\"-\"*80)\n",
    "qualifying = df_best[df_best['numerator_met']==True]\n",
    "if not qualifying.empty:\n",
    "    print(f\"  Mean confidence: {qualifying['best_confidence'].mean():.2f}\")\n",
    "    print(f\"  Min confidence: {qualifying['best_confidence'].min():.2f}\")\n",
    "    print(f\"  Max confidence: {qualifying['best_confidence'].max():.2f}\")\n",
    "    print(f\"  High confidence (≥0.85): {(qualifying['best_confidence']>=0.85).sum()} patients\")\n",
    "    print(f\"  Medium confidence (0.65-0.84): {((qualifying['best_confidence']>=0.65) & (qualifying['best_confidence']<0.85)).sum()} patients\")\n",
    "    print(f\"  Low confidence (<0.65): {(qualifying['best_confidence']<0.65).sum()} patients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df9a289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG: Check what pdfplumber extracts vs what's actually in a sample PDF\n",
    "# Update this path to point to an actual mammogram PDF in your data\n",
    "test_pdf = \"pdf_data/sample_mammogram.pdf\"\n",
    "\n",
    "if os.path.exists(test_pdf):\n",
    "    print(\"=\"*80)\n",
    "    print(\"PDFPLUMBER EXTRACTION:\")\n",
    "    print(\"=\"*80)\n",
    "    try:\n",
    "        with pdfplumber.open(test_pdf) as pdf:\n",
    "            print(f\"Total pages: {len(pdf.pages)}\")\n",
    "            for i, page in enumerate(pdf.pages[:3]):  # Check first 3 pages\n",
    "                text = page.extract_text()\n",
    "                print(f\"\\n--- Page {i+1} (length: {len(text) if text else 0}) ---\")\n",
    "                print(text[:1000] if text else \"No text extracted\")\n",
    "                print()\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"TRYING OCR with POPPLER_PATH={POPPLER_PATH}:\")\n",
    "    print(\"=\"*80)\n",
    "    try:\n",
    "        pages = convert_from_path(test_pdf, dpi=150, first_page=1, last_page=1, poppler_path=POPPLER_PATH)\n",
    "        if pages:\n",
    "            ocr_text = pytesseract.image_to_string(pages[0])\n",
    "            print(f\"✓ OCR SUCCESS! Extracted {len(ocr_text)} chars\")\n",
    "            print(f\"OCR text (first 1000 chars):\\n{ocr_text[:1000]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ OCR failed: {e}\")\n",
    "else:\n",
    "    print(f\"⚠️ Test PDF not found: {test_pdf}\")\n",
    "    print(\"Update the 'test_pdf' variable to point to an actual mammogram PDF in your pdf_data folder\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
